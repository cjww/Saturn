#version 420
#extension GL_ARB_compute_shader : enable
layout (local_size_x = 32, local_size_y = 32) in;

layout(set = 0, binding = 0) uniform sampler2D colorImage; // original color
layout(set = 0, binding = 1, rgba8) uniform readonly image2D inputImage1; // input 1
layout(set = 0, binding = 2, rgba8) uniform readonly image2D inputImage2; // input 2
layout(set = 0, binding = 3, rgba8) uniform writeonly image2D resultImage; // result

const int MODE_FILTER = 0;
const int MODE_DOWNSAMPLE = 1;
const int MODE_UPSAMPLE = 2;
const int MODE_COMBINE = 3;


layout(push_constant) uniform PushConstant {
    int mode;
} pc;

struct GaussianData {
    float normFactor;
    int kernelRadius;
    float kernel[13];
};

struct TonemapPreferences {
  float gamma;
  float exposure;
  int tonemappingAlgorithm;
};

layout(set = 1, binding = 0) uniform BloomPreferences {
    float threshold;
    float intensity;
    TonemapPreferences tonemapPreferences;
    GaussianData gaussData;
} bloomPreferences;

float normpdf(in float x, in float sigma)
{
	return 0.39894*exp(-0.5*x*x/(sigma*sigma))/sigma;
}

vec3 gaussian(ivec2 pos) {
	//declare stuff
	const int mSize = 7;
	const int kSize = (mSize - 1) / 2;
	float kernel[mSize];
	vec3 final_colour = vec3(0.0);
	
	//create the 1-D kernel
	float sigma = 7.0;
	float Z = 0.0;
	for (int j = 0; j <= kSize; ++j) {
		kernel[kSize + j] = kernel[kSize - j] = normpdf(float(j), sigma);
	}
	
	//get the normalization factor (as the gaussian has been clamped)
	for (int j = 0; j < mSize; ++j) {
		Z += kernel[j];
	}

	vec2 textureSize = textureSize(colorImage, 0);
	//read out the texels
	for (int i= -kSize; i <= kSize; ++i) {
		for (int j= -kSize; j <= kSize; ++j) {
			ivec2 samplePos = (pos + ivec2(i, j)) * 2;
			final_colour += kernel[kSize + j] * kernel[kSize + i] * imageLoad(inputImage1, samplePos).rgb;
		}
	}
	return final_colour / (Z*Z);
}
/*
*/
vec3 gaussian1(ivec2 pos) {
	//declare stuff
	const int kSize = bloomPreferences.gaussData.kernelRadius;
	vec3 final_colour = vec3(0.0);

	//read out the texels
	for (int i= -kSize; i <= kSize; ++i) {
		for (int j= -kSize; j <= kSize; ++j) {
			ivec2 samplePos = (pos + ivec2(i, j)) * 2;
			final_colour += bloomPreferences.gaussData.kernel[kSize + j] * bloomPreferences.gaussData.kernel[kSize + i] * imageLoad(inputImage1, samplePos).rgb;
		}
	}
	return final_colour / bloomPreferences.gaussData.normFactor;
}


// [Jimenez14] http://goo.gl/eomGso
// . . . . . . .
// . A . B . C .
// . . D . E . .
// . F . G . H .
// . . I . J . .
// . K . L . M .
// . . . . . . .
vec4 downsample(in sampler2D image, vec2 uv, vec2 texelSize) {
	vec4 A = texture(image, uv + texelSize * vec2(-1.0, -1.0));
    vec4 B = texture(image, uv + texelSize * vec2( 0.0, -1.0));
    vec4 C = texture(image, uv + texelSize * vec2( 1.0, -1.0));
    vec4 D = texture(image, uv + texelSize * vec2(-0.5, -0.5));
    vec4 E = texture(image, uv + texelSize * vec2( 0.5, -0.5));
    vec4 F = texture(image, uv + texelSize * vec2(-1.0,  0.0));
    vec4 G = texture(image, uv);
    vec4 H = texture(image, uv + texelSize * vec2( 1.0,  0.0));
    vec4 I = texture(image, uv + texelSize * vec2(-0.5,  0.5));
    vec4 J = texture(image, uv + texelSize * vec2( 0.5,  0.5));
    vec4 K = texture(image, uv + texelSize * vec2(-1.0,  1.0));
    vec4 L = texture(image, uv + texelSize * vec2( 0.0,  1.0));
    vec4 M = texture(image, uv + texelSize * vec2( 1.0,  1.0));

    vec4 o = (D + E + I + J) * (0.25 * 0.5);
    o += (A + B + G + F) * (0.25 * 0.125);
    o += (B + C + H + G) * (0.25 * 0.125);
    o += (F + G + L + K) * (0.25 * 0.125);
    o += (G + H + M + L) * (0.25 * 0.125);

    return o;
}

vec4 downsample(ivec2 coordinate) {
	vec4 A = imageLoad(inputImage1, coordinate * ivec2(-2, -2));
    vec4 B = imageLoad(inputImage1, coordinate * ivec2( 0, -2));
    vec4 C = imageLoad(inputImage1, coordinate * ivec2( 2, -2));
    vec4 D = imageLoad(inputImage1, coordinate * ivec2(-1, -1));
    vec4 E = imageLoad(inputImage1, coordinate * ivec2( 1, -1));
    vec4 F = imageLoad(inputImage1, coordinate * ivec2(-2,  0));
    vec4 G = imageLoad(inputImage1, coordinate);
    vec4 H = imageLoad(inputImage1, coordinate + ivec2( 2,  0));
    vec4 I = imageLoad(inputImage1, coordinate + ivec2(-1,  1));
    vec4 J = imageLoad(inputImage1, coordinate + ivec2( 1,  1));
    vec4 K = imageLoad(inputImage1, coordinate + ivec2(-2,  2));
    vec4 L = imageLoad(inputImage1, coordinate + ivec2( 0,  2));
    vec4 M = imageLoad(inputImage1, coordinate + ivec2( 2,  2));

    vec4 o = (D + E + I + J) * (0.25 * 0.5);
    o += (A + B + G + F) * (0.25 * 0.125);
    o += (B + C + H + G) * (0.25 * 0.125);
    o += (F + G + L + K) * (0.25 * 0.125);
    o += (G + H + M + L) * (0.25 * 0.125);

    return o;
}

vec4 upsample(ivec2 coordinate) {
    vec4 s;
	s =  imageLoad(inputImage1, ivec2(coordinate + ivec2(1, 1)));
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(0, 1))) * 2.0;
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(-1, 1)));
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(1, 0))) * 2.0;
    s += imageLoad(inputImage1, ivec2(coordinate				 )) * 4.0;
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(-1, 0))) * 2.0;
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(1, -1)));
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(0, -1))) * 2.0;
    s += imageLoad(inputImage1, ivec2(coordinate + ivec2(-1, -1)));

    return s * (1.0 / 16.0);
}

vec3 filterThreshold(vec3 color, float threshold) {
	float brightness = max(color.r, max(color.g, color.b));
    float contribution = max(0, brightness - threshold);
	contribution /= max(brightness, 0.00001);
    return color * contribution;
}

vec3 aces_approx(vec3 v) {
    float a = 2.51;
    float b = 0.03;
    float c = 2.43;
    float d = 0.59;
    float e = 0.14;
    return clamp((v*(a*v+b))/(v*(c*v+d)+e), 0.0, 1.0);
}


vec3 uncharted2_tonemap_partial(vec3 x)
{
    float A = 0.15;
    float B = 0.50;
    float C = 0.10;
    float D = 0.20;
    float E = 0.02;
    float F = 0.30;
    return ((x*(A*x+C*B)+D*E)/(x*(A*x+B)+D*F))-E/F;
}

vec3 uncharted2_filmic(vec3 v)
{
    float exposure_bias = 2.0;
    vec3 curr = uncharted2_tonemap_partial(v * exposure_bias);

    vec3 W = vec3(11.2);
    vec3 white_scale = vec3(1.0) / uncharted2_tonemap_partial(W);
    return curr * white_scale;
}

vec3 reinhard(vec3 v) {
    return v / (1.0 + v);
}

float luminance(vec3 v) {
    return dot(v, vec3(0.2126, 0.7152, 0.0722));
}

vec3 change_luminance(vec3 c_in, float l_out) {
    float l_in = luminance(c_in);
    return c_in * (l_out / l_in);
}

vec3 reinhard_extended_luminance(vec3 v, float max_white_l) {
    float l_old = luminance(v);
    float numerator = l_old * (1.0 + (l_old / (max_white_l * max_white_l)));
    float l_new = numerator / (1.0 + l_old);
    return change_luminance(v, l_new);
}

vec3 gammaCorrect(vec3 color, float gamma) {
    return pow(color, vec3(1.0 / gamma));
}

void main() {
    ivec2 pos = ivec2(gl_GlobalInvocationID.xy); // coordinates on result image
    
    vec2 texSize = textureSize(colorImage, 0);
    vec2 uv = vec2(pos) / texSize;
    
    vec3 color = vec3(0);
    if(pc.mode == MODE_FILTER) {
        //pass 1
	    color = downsample(colorImage, uv * 2, 1 / texSize).rgb;
        color = filterThreshold(color, bloomPreferences.threshold); // filter color
    }
    else if(pc.mode == MODE_DOWNSAMPLE) {
        //pass 2
        color = gaussian1(pos); // downsample and blur
    }
    else if(pc.mode == MODE_UPSAMPLE) {
        //pass 3
        ivec2 posSmall = ivec2(pos * 0.5);
        color = upsample(posSmall).rgb;
        color += imageLoad(inputImage2, pos).rgb;
    }
    else if(pc.mode == MODE_COMBINE) {
        //pass 4
        color = texture(colorImage, uv).rgb;
        
        ivec2 posSmall = ivec2(pos * 0.5);
        vec3 bloom = upsample(posSmall).rgb;
        color += bloom * bloomPreferences.intensity;

        //tonemap
        color *= bloomPreferences.tonemapPreferences.exposure;
        color = aces_approx(color);
        color = gammaCorrect(color, bloomPreferences.tonemapPreferences.gamma);
    }
    
	imageStore(resultImage, pos, vec4(color, 1.0));
}